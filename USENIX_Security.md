# USENIX Security Papers

### SEC 2022

**Accepted Papers ([Summer](https://www.usenix.org/conference/usenixsecurity22/summer-accepted-papers), [Fall](https://www.usenix.org/conference/usenixsecurity22/fall-accepted-papers), [Winter](https://www.usenix.org/conference/usenixsecurity22/winter-accepted-papers))**

| Topic                           | Title                                                        |
| ------------------------------- | ------------------------------------------------------------ |
| **Differential Privacy**        | [Pool Inference Attacks on Local Differential Privacy: Quantifying the Privacy Guarantees of Apple's Count Mean Sketch in Practice](https://www.usenix.org/conference/usenixsecurity22/presentation/gadotti) |
|                                 | [Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data](https://www.usenix.org/conference/usenixsecurity22/presentation/wu-yongji) |
|                                 | [Communication-Efficient Triangle Counting under Local Differential Privacy](https://www.usenix.org/conference/usenixsecurity22/presentation/imola) |
|                                 | [Twilight: A Differentially Private Payment Channel Network](https://www.usenix.org/conference/usenixsecurity22/presentation/dotan) |
| **Federated Learning**          | [SIMC: ML Inference Secure Against Malicious Clients at Semi-Honest Cost](https://www.usenix.org/conference/usenixsecurity22/presentation/chandran) |
|                                 | [Efficient Differentially Private Secure Aggregation for Federated Learning via Hardness of Learning with Errors](https://www.usenix.org/conference/usenixsecurity22/presentation/stevens) |
|                                 | [Label Inference Attacks Against Vertical Federated Learning](https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong) |
|                                 | [FLAME: Taming Backdoors in Federated Learning](https://www.usenix.org/conference/usenixsecurity22/presentation/nguyen) |
| **Deanonymization**             | [Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture](https://www.usenix.org/conference/usenixsecurity22/presentation/tang) |
|                                 | [Synthetic Data – Anonymisation Groundhog Day](https://www.usenix.org/conference/usenixsecurity22/presentation/stadler) |
|                                 | [Attacks on Deidentification's Defenses](https://www.usenix.org/conference/usenixsecurity22/presentation/cohen) |
|                                 | [Birds of a Feather Flock Together: How Set Bias Helps to Deanonymize You via Revealed Intersection Sizes](https://www.usenix.org/conference/usenixsecurity22/presentation/guo) |
|                                 | [Targeted Deanonymization via the Cache Side Channel: Attacks and Defenses](https://www.usenix.org/conference/usenixsecurity22/presentation/zaheri) |
| **Machine Learning I**          | [PatchCleanser: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier](https://www.usenix.org/conference/usenixsecurity22/presentation/xiang) |
|                                 | [Transferring Adversarial Robustness Through Robust Representation Matching](https://www.usenix.org/conference/usenixsecurity22/presentation/vaishnavi) |
|                                 | [How Machine Learning Is Solving the Binary Function Similarity Problem](https://www.usenix.org/conference/usenixsecurity22/presentation/marcelli) |
|                                 | [Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks](https://www.usenix.org/conference/usenixsecurity22/presentation/li-huiying) |
|                                 | [DnD: A Cross-Architecture Deep Neural Network Decompiler](https://www.usenix.org/conference/usenixsecurity22/presentation/wu-ruoyu) |
| **Machine Learning II**         | [Towards More Robust Keyword Spotting for Voice Assistants](https://www.usenix.org/conference/usenixsecurity22/presentation/ahmed) |
|                                 | [Seeing is Living? Rethinking the Security of Facial Liveness Verification in the Deepfake Era](https://www.usenix.org/conference/usenixsecurity22/presentation/li-changjiang) |
|                                 | [Who Are You (I Really Wanna Know)? Detecting Audio DeepFakes Through Vocal Tract Reconstruction](https://www.usenix.org/conference/usenixsecurity22/presentation/blue) |
|                                 | [DeepDi: Learning a Relational Graph Convolutional Network Model on Instructions for Fast and Accurate Disassembly](https://www.usenix.org/conference/usenixsecurity22/presentation/yu-sheng) |
| **ML Attacks**                  | [AutoDA: Automated Decision-based Iterative Adversarial Attacks](https://www.usenix.org/conference/usenixsecurity22/presentation/fu-qi) |
|                                 | [Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks](https://www.usenix.org/conference/usenixsecurity22/presentation/shan) |
|                                 | [Teacher Model Fingerprinting Attacks Against Transfer Learning](https://www.usenix.org/conference/usenixsecurity22/presentation/chen-yufei) |
|                                 | [Hidden Trigger Backdoor Attack on NLP Models via Linguistic Style Manipulation](https://www.usenix.org/conference/usenixsecurity22/presentation/pan-hidden) |
|                                 | [PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in Contrastive Learning](https://www.usenix.org/conference/usenixsecurity22/presentation/liu-hongbin) |
| **Principles & Best Practices** | [On the Security Risks of AutoML](https://www.usenix.org/conference/usenixsecurity22/presentation/pang-ren) |
|                                 | [Dos and Don'ts of Machine Learning in Computer Security](https://www.usenix.org/conference/usenixsecurity22/presentation/arp) |
|                                 | [Exploring the Security Boundary of Data Reconstruction via Neuron Exclusivity Analysis](https://www.usenix.org/conference/usenixsecurity22/presentation/pan-exploring) |
|                                 | [On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning](https://www.usenix.org/conference/usenixsecurity22/presentation/thudi) |
| **Performance Improvements**    | [Cheetah: Lean and Fast Secure Two-Party Deep Neural Network Inference](https://www.usenix.org/conference/usenixsecurity22/presentation/huang-zhicong) |
|                                 | [Piranha: A GPU Platform for Secure Computation](https://www.usenix.org/conference/usenixsecurity22/presentation/watson) |
| **ML Inference**                | [ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models](https://www.usenix.org/conference/usenixsecurity22/presentation/liu-yugeng) |
|                                 | [Inference Attacks Against Graph Neural Networks](https://www.usenix.org/conference/usenixsecurity22/presentation/zhang-zhikun) |
|                                 | [Membership Inference Attacks and Defenses in Neural Network Pruning](https://www.usenix.org/conference/usenixsecurity22/presentation/yuan-xiaoyong) |
|                                 | [Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classification Models](https://www.usenix.org/conference/usenixsecurity22/presentation/mehnaz) |
| **Side Channels**               | [Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel](https://www.usenix.org/conference/usenixsecurity22/presentation/maia) |
| **Smart Vehicles**              | [Rolling Colors: Adversarial Laser Exploits against Traffic Light Recognition](https://www.usenix.org/conference/usenixsecurity22/presentation/yan) |
| **Client-Side Security**        | [Adversarial Detection Avoidance Attacks: Evaluating the robustness of perceptual hashing-based client-side scanning](https://www.usenix.org/conference/usenixsecurity22/presentation/jain) |



### SEC 2021

**Accepted Papers ([Summer](https://www.usenix.org/conference/usenixsecurity21/summer-accepted-papers), [Fall](https://www.usenix.org/conference/usenixsecurity21/fall-accepted-papers))**

| Topic                                          | Title                                                        |
| ---------------------------------------------- | ------------------------------------------------------------ |
| **Private Computation & Differential Privacy** | [Private Blocklist Lookups with Checklist](https://www.usenix.org/conference/usenixsecurity21/presentation/kogan) |
|                                                | [Identifying Harmful Media in End-to-End Encrypted Communication: Efficient Private Membership Computation](https://www.usenix.org/conference/usenixsecurity21/presentation/kulshrestha) |
|                                                | [Fuzzy Labeled Private Set Intersection with Applications to Private Real-Time Biometric Search](https://www.usenix.org/conference/usenixsecurity21/presentation/uzun) |
|                                                | [PrivSyn: Differentially Private Data Synthesis](https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-zhikun) |
|                                                | [Data Poisoning Attacks to Local Differential Privacy Protocols](https://www.usenix.org/conference/usenixsecurity21/presentation/cao-xiaoyu) |
|                                                | [How to Make Private Distributed Cardinality Estimation Practical, and Get Differential Privacy for Free](https://www.usenix.org/conference/usenixsecurity21/presentation/hu-changhui) |
|                                                | [Locally Differentially Private Analysis of Graph Statistics](https://www.usenix.org/conference/usenixsecurity21/presentation/imola) |
| **Backdoor & Poisoning**                       | [Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers](https://www.usenix.org/conference/usenixsecurity21/presentation/severi) |
|                                                | [Blind Backdoors in Deep Learning Models](https://www.usenix.org/conference/usenixsecurity21/presentation/bagdasaryan) |
|                                                | [Graph Backdoor](https://www.usenix.org/conference/usenixsecurity21/presentation/xi) |
|                                                | [Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection](https://www.usenix.org/conference/usenixsecurity21/presentation/tang-di) |
|                                                | [You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion](https://www.usenix.org/conference/usenixsecurity21/presentation/schuster) |
|                                                | [Poisoning the Unlabeled Dataset of Semi-Supervised Learning](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-poisoning) |
|                                                | [Double-Cross Attacks: Subverting Active Learning Systems](https://www.usenix.org/conference/usenixsecurity21/presentation/vicarte) |
| **Adversarial Examples & Model Extraction**    | [SLAP: Improving Physical Adversarial Examples with Short-Lived Adversarial Perturbations](https://www.usenix.org/conference/usenixsecurity21/presentation/lovisotto) |
|                                                | [Adversarial Policy Training against Deep Reinforcement Learning](https://www.usenix.org/conference/usenixsecurity21/presentation/wu-xian) |
|                                                | [DRMI: A Dataset Reduction Technology based on Mutual Information for Black-box Attacks](https://www.usenix.org/conference/usenixsecurity21/presentation/he-yingzhe) |
|                                                | [Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush Deep Neural Network in Multi-Tenant FPGA](https://www.usenix.org/conference/usenixsecurity21/presentation/rakin) |
|                                                | [Entangled Watermarks as a Defense against Model Extraction](https://www.usenix.org/conference/usenixsecurity21/presentation/jia) |
|                                                | [Mind Your Weight(s): A Large-scale Study on Insufficient Machine Learning Model Protection in Mobile Apps](https://www.usenix.org/conference/usenixsecurity21/presentation/sun-zhichuang) |
|                                                | [Hermes Attack: Steal DNN Models with Lossless Inference Accuracy](https://www.usenix.org/conference/usenixsecurity21/presentation/zhu) |
| **Secure Multiparty Computation**              | [GForce: GPU-Friendly Oblivious and Rapid Neural Network Inference](https://www.usenix.org/conference/usenixsecurity21/presentation/ng) |
|                                                | [Fantastic Four: Honest-Majority Four-Party Secure Computation With Malicious Security](https://www.usenix.org/conference/usenixsecurity21/presentation/dalskov) |
|                                                | [Muse: Secure Inference Resilient to Malicious Clients](https://www.usenix.org/conference/usenixsecurity21/presentation/lehmkuhl) |
| **Adversarial ML Defenses**                    | [PatchGuard: A Provably Robust Defense against Adversarial Patches via Small Receptive Fields and Masking](https://www.usenix.org/conference/usenixsecurity21/presentation/xiang) |
|                                                | [T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification](https://www.usenix.org/conference/usenixsecurity21/presentation/azizi) |
|                                                | [WaveGuard: Understanding and Mitigating Audio Adversarial Examples](https://www.usenix.org/conference/usenixsecurity21/presentation/hussain) |
|                                                | [Cost-Aware Robust Tree Ensembles for Security Applications](https://www.usenix.org/conference/usenixsecurity21/presentation/chen-yizheng) |
|                                                | [Dompteur: Taming Audio Adversarial Examples](https://www.usenix.org/conference/usenixsecurity21/presentation/eisenhofer) |
|                                                | [CADE: Detecting and Explaining Concept Drift Samples for Security Applications](https://www.usenix.org/conference/usenixsecurity21/presentation/yang-limin) |
|                                                | [SIGL: Securing Software Installations Through Deep Graph Learning](https://www.usenix.org/conference/usenixsecurity21/presentation/han-xueyuan) |
| **ML Privacy Issues**                          | [Systematic Evaluation of Privacy Risks of Machine Learning Models](https://www.usenix.org/conference/usenixsecurity21/presentation/song) |
|                                                | [Extracting Training Data from Large Language Models](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting) |
|                                                | [SWIFT: Super-fast and Robust Privacy-Preserving Machine Learning](https://www.usenix.org/conference/usenixsecurity21/presentation/koti) |
|                                                | [Stealing Links from Graph Neural Networks](https://www.usenix.org/conference/usenixsecurity21/presentation/he-xinlei) |
|                                                | [Leakage of Dataset Properties in Multi-Party Machine Learning](https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-wanrong) |
|                                                | [Defeating DNN-Based Traffic Analysis Systems in Real-Time With Blind Adversarial Perturbations](https://www.usenix.org/conference/usenixsecurity21/presentation/nasr) |
|                                                | [Cerebro: A Platform for Multi-Party Cryptographic Collaborative Learning](https://www.usenix.org/conference/usenixsecurity21/presentation/zheng) |
| **Attacks**                                    | [Too Good to Be Safe: Tricking Lane Detection in Autonomous Driving with Crafted Perturbations](https://www.usenix.org/conference/usenixsecurity21/presentation/jing) |
|                                                | [Research on the Security of Visual Reasoning CAPTCHA](https://www.usenix.org/conference/usenixsecurity21/presentation/gao) |
|                                                | [Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack](https://www.usenix.org/conference/usenixsecurity21/presentation/sato) |



### SEC 2020

**Accepted Papers ([Spring](https://www.usenix.org/conference/usenixsecurity20/spring-accepted-papers), [Summer](https://www.usenix.org/conference/usenixsecurity20/summer-accepted-papers), [Fall](https://www.usenix.org/conference/usenixsecurity20/fall-accepted-papers))**

| Topic                              | Title                                                        |
| ---------------------------------- | ------------------------------------------------------------ |
| **Privacy Enhancing Technologies** | [PCKV: Locally Differentially Private Correlated Key-Value Data Collection with Optimized Utility](https://www.usenix.org/conference/usenixsecurity20/presentation/gu) |
|                                    | [Actions Speak Louder than Words: Entity-Sensitive Privacy Policy and Data Flow Analysis with PoliCheck](https://www.usenix.org/conference/usenixsecurity20/presentation/andow) |
|                                    | [Walking Onions: Scaling Anonymity Networks while Protecting Users](https://www.usenix.org/conference/usenixsecurity20/presentation/komlo) |
|                                    | [Differentially-Private Control-Flow Node Coverage for Software Usage Analysis](https://www.usenix.org/conference/usenixsecurity20/presentation/zhang-hailong) |
|                                    | [Visor: Privacy-Preserving Video Analytics as a Cloud Service](https://www.usenix.org/conference/usenixsecurity20/presentation/poddar) |
|                                    | [DELF: Safeguarding deletion correctness in Online Social Networks](https://www.usenix.org/conference/usenixsecurity20/presentation/cohn-gordon) |
| **Machine Learning 1**             | [Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning](https://www.usenix.org/conference/usenixsecurity20/presentation/salem) |
|                                    | [Exploring Connections Between Active Learning and Model Extraction](https://www.usenix.org/conference/usenixsecurity20/presentation/chandrasekaran) |
|                                    | [Hybrid Batch Attacks: Finding Black-box Adversarial Examples with Limited Queries](https://www.usenix.org/conference/usenixsecurity20/presentation/suya) |
|                                    | [High Accuracy and High Fidelity Extraction of Neural Networks](https://www.usenix.org/conference/usenixsecurity20/presentation/jagielski) |
|                                    | [Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning](https://www.usenix.org/conference/usenixsecurity20/presentation/quiring) |
|                                    | [TextShield: Robust Text Classification Based on Multimodal Embedding and Neural Machine Translation](https://www.usenix.org/conference/usenixsecurity20/presentation/li-jinfeng) |
| **Machine Learning 2**             | [Fawkes: Protecting Privacy against Unauthorized Deep Learning Models](https://www.usenix.org/conference/usenixsecurity20/presentation/shan) |
|                                    | [Stolen Memories: Leveraging Model Memorization for Calibrated White-Box Membership Inference](https://www.usenix.org/conference/usenixsecurity20/presentation/leino) |
|                                    | [Local Model Poisoning Attacks to Byzantine-Robust Federated Learning](https://www.usenix.org/conference/usenixsecurity20/presentation/fang) |
|                                    | [Justinian's GAAvernor: Robust Distributed Learning with Gradient Aggregation Agent](https://www.usenix.org/conference/usenixsecurity20/presentation/pan) |
|                                    | [Interpretable Deep Learning under Fire](https://www.usenix.org/conference/usenixsecurity20/presentation/zhang-xinyang) |
| **Implementations of Crypto**      | [Secure Multi-party Computation of Differentially Private Median](https://www.usenix.org/conference/usenixsecurity20/presentation/boehler) |
| **Secure Computation**             | [Delphi: A Cryptographic Inference Service for Neural Networks](https://www.usenix.org/conference/usenixsecurity20/presentation/mishra) |
| **Voice and Speech**               | [Devil’s Whisper: A General Approach for Physical Adversarial Attacks against Commercial Black-box Speech Recognition Devices](https://www.usenix.org/conference/usenixsecurity20/presentation/chen-yuxuan) |
